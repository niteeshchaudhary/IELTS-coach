ğŸ™ï¸ IELTS English Speaking Coach (AI Tutor)
ğŸ“Œ PURPOSE OF THIS README (IMPORTANT)

This README exists to lock product vision, constraints, and design intent so that any agentic AI (or future contributor) does not drift, simplify, or misunderstand the goals.

This is NOT a demo app.
This is a human-like, voice-first IELTS English tutor.

ğŸ¯ PRODUCT VISION

Build an AI-powered English Speaking Coach focused on IELTS that feels like:

â€œI am talking to a real, patient English tutor who listens, waits, thinks, and responds naturally.â€

The app must:

Improve spoken English

Improve IELTS band score

Encourage daily practice

Feel non-robotic and interruption-aware

ğŸ§± NON-NEGOTIABLE CONSTRAINTS
Technology

Language: Python only

Frontend: Streamlit

Backend: Streamlit (same codebase)

Runs locally

LLM-driven logic

UX Rules

âŒ No â€œStop Speakingâ€ button
âŒ No push-to-talk UX
âŒ No text-only chatbot experience

âœ… Auto pause detection
âœ… Natural waiting
âœ… Voice-first interaction

ğŸ§  CORE INTELLIGENCE REQUIREMENTS
1ï¸âƒ£ Daily IELTS Vocabulary System

Every day the app must:

Select IELTS-relevant vocabulary

Provide:

Meaning

Example sentences

Usage notes

Common mistakes

Actively initiate conversation to force usage

Detect:

Correct usage

Incorrect usage

Partial usage

Provide gentle corrections, never harsh feedback

2ï¸âƒ£ Real Human-Like Conversation

The system must support:

Voice input

Voice output

Natural turn-taking

Context memory

The user should feel:

The AI listens fully

The AI waits if the user pauses

The AI does not interrupt

The AI responds intelligently

3ï¸âƒ£ Automatic Pause Detection (CRITICAL FEATURE)

The app must:

Detect long pauses (â‰ˆ1.5â€“2.5 seconds)

Automatically treat silence as:

End of user turn

Never require the user to say â€œIâ€™m doneâ€

4ï¸âƒ£ Smart Response Buffering (VERY IMPORTANT)

While the user is speaking:

AI may prepare a response

AI must NOT speak immediately

After user stops:

Decide whether to:

Continue buffered response

Drop buffered response

Merge buffer + user reply

Decision must be based on:

Relevance

Conversation flow

Importance of buffered content

This logic must be explicitly coded, not assumed.

ğŸ—£ï¸ VOICE PIPELINE REQUIREMENTS
Speech-to-Text (STT)

Streaming capable

Accurate for non-native accents

Supports pause detection

Examples:

Whisper / Faster-Whisper

Vosk

Text-to-Speech (TTS)

Free or open-source

Natural sounding

ElevenLabs-like quality preferred

Examples:

Coqui TTS

Piper

Bark (if feasible)

ğŸ–¥ï¸ UI REQUIREMENTS (Streamlit)

The UI must include:

ğŸ™ï¸ Live microphone capture

ğŸ“ Live transcription

ğŸ”Š Audio playback

ğŸ“˜ Word of the Day

ğŸ® Games section

ğŸ§ª IELTS tests section

ğŸ“Š Progress tracking

ğŸ® LEARNING FEATURES
Vocabulary & Typing Games

Word matching

Sentence completion

Typing accuracy & speed

Error correction tasks

IELTS Practice Modules

Listening test

Reading test

Speaking test

(Optional) Writing prompts

â° Vocabulary Reinforcement

Same Word of the Day repeated:

During conversations

In reminders

In games

Reinforcement throughout the day

ğŸ“˜ IELTS GUIDANCE MODULE

The app must include structured guidance for:

IELTS exam format

Band score criteria

Common mistakes

Daily preparation plan

Mock test strategies

Exam-day tips

ğŸ§© ARCHITECTURE EXPECTATIONS

The system must clearly define:

Conversation state machine

Audio pipeline

Buffering logic

LLM prompt layers

Memory handling

Modular components

The agent must not collapse everything into one script.

ğŸ› ï¸ EXPECTED OUTPUT FROM AGENTIC AI

The agent must deliver:

Architecture explanation

Component-level design

Exact Python libraries used

Streamlit app structure

Pause detection logic

Buffer decision pseudocode

LLM system + user prompts

Working end-to-end code

Local run instructions

Scalability notes

ğŸš« ANTI-GOALS (DO NOT DO THIS)

âŒ Simple chatbot

âŒ Text-only IELTS app

âŒ Button-driven conversation

âŒ Ignoring pause/buffer logic

âŒ â€œDemo-levelâ€ shortcuts

âœ… SUCCESS CRITERIA

This project is successful only if:

User can speak naturally

User can pause freely

AI responds like a human tutor

IELTS vocabulary improves measurably

App feels conversational, not transactional

ğŸš€ HOW TO RUN

Prerequisites

- Python 3.10+
- ~4 GB RAM (for audio models: Silero VAD, Faster-Whisper, Piper TTS)
- A working microphone (for voice mode; text fallback available)

1. Install Dependencies

```bash
cd eng_prep
pip install -r requirements.txt
```

2. Configure LLM Provider

Choose ONE of the following:

Option A â€” OpenAI (default):
```bash
export OPENAI_API_KEY="sk-your-key-here"
```

Option B â€” Google Gemini:
```bash
export LLM_PROVIDER="gemini"
export GEMINI_API_KEY="your-gemini-key"
```

Option C â€” Ollama (fully local, no API key needed):
```bash
export LLM_PROVIDER="ollama"
export LLM_MODEL="deepseek-r1:latest"
# Make sure Ollama is running: ollama serve
```

3. Run the App

```bash
streamlit run app.py
```

The app will open at http://localhost:8501.

Pages

- ğŸ™ï¸ Conversation â€” Voice or text chat with your AI tutor
- ğŸ“˜ Word of the Day â€” Daily IELTS vocabulary cards + practice
- ğŸ® Games â€” Word matching, sentence completion, typing speed, error correction
- ğŸ§ª IELTS Practice â€” Speaking Part 1, 2, 3 with band score evaluation
- ğŸ“Š Progress â€” Dashboard with streaks, vocabulary mastery, daily activity
- ğŸ“– IELTS Guide â€” Exam format, band criteria, common mistakes, tips

Notes

- First launch downloads audio models (~500 MB). Subsequent launches are faster.
- If WebRTC microphone is unavailable, the app falls back to text input automatically.
- All progress is stored locally in `data/user_progress.db` (SQLite).
- Configuration parameters are in `config.py` â€” no magic numbers elsewhere.

ğŸ§  FINAL NOTE TO AGENTIC AI

Preserve this context at all times.
If any design decision conflicts with this README, this README wins.